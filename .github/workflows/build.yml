name: Scrape Releases
permissions:
  contents: write

env:
  URLS: ${{ secrets.URLS }}
  PRODUCT_LINK_CSS_SELECTOR: ${{ secrets.PRODUCT_LINK_CSS_SELECTOR }}
  SUGGESTED_STOCK_AMOUNT_CSS_SELECTOR: ${{ secrets.SUGGESTED_STOCK_AMOUNT_CSS_SELECTOR }}
  SUGGESTED_STOCK_AMOUNT_ATTRIBUTE_NAME: ${{ secrets.SUGGESTED_STOCK_AMOUNT_ATTRIBUTE_NAME }}
  INPUT_PURCHASE_AMOUNT_CSS_SELECTOR: ${{ secrets.INPUT_PURCHASE_AMOUNT_CSS_SELECTOR }}
  PURCHASE_SUBMIT_CSS_SELECTOR: ${{ secrets.PURCHASE_SUBMIT_CSS_SELECTOR }}

  PRODUCT_NAME_CSS_SELECTOR: ${{ secrets.PRODUCT_NAME_CSS_SELECTOR }}
  PRODUCT_BRAND_CSS_SELECTOR: ${{ secrets.PRODUCT_BRAND_CSS_SELECTOR }}
  PRODUCT_PRICE_CSS_SELECTOR: ${{ secrets.PRODUCT_PRICE_CSS_SELECTOR }}
  PRODUCT_PRICE_CURRENCY_CSS_SELECTOR: ${{ secrets.PRODUCT_PRICE_CURRENCY_CSS_SELECTOR }}
  PRODUCT_AVAILABILITY_CSS_SELECTOR: ${{ secrets.PRODUCT_AVAILABILITY_CSS_SELECTOR }}

  WEBHOOK_PRODUCTION_ENDPOINT: ${{ secrets.WEBHOOK_PRODUCTION_ENDPOINT }}

on:
  push:
    branches:
      - main
  #schedule:
  #  - cron: "0 8 * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: üõí Checkout the repo
        uses: actions/checkout@v3

      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
          cache: 'pip'
      - run: pip install -r requirements.txt

      - name: üï∏Ô∏è Run crawler
        run: |
            python crawler.py
        shell: bash

      - name: ‚úÖ Validate stuff
        run: |
            [ -s "${{ github.workspace }}/stocks.json" ] && echo "üéâ Stocks JSON generated successfully!" || exit 1
        shell: bash


      - name: ü§ñ Send to n8n Webhook
        uses: fjogeleit/http-request-action@v1
        with:
          url: '${{ env.WEBHOOK_PRODUCTION_ENDPOINT }}'
          method: 'POST'
          file: ${{ github.workspace }}/stocks.json


